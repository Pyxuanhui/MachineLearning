{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e501a38b",
   "metadata": {},
   "source": [
    "# KNN算法（K-Nearest Neighbors）\n",
    "\n",
    "- KNN算法是一种基本且常用的机器学习算法，主要用于分类和回归任务。它基于“近邻”思想，即通过测量数据点之间的距离来进行预测。以下是KNN算法的基本原理和步骤：\n",
    "\n",
    "### 基本思想\n",
    "\n",
    "- 如果一个样本，在特征空间中的**k个最相似的样本**中的大多数属于某一个类别，则该样本也属于这个类别。一般来通过两个样本之间的距离来确定它们的相似程度。\n",
    "\n",
    "### 距离计算公式\n",
    "\n",
    "#### 欧氏距离(Euclidean distance)\n",
    "\n",
    "欧几里得度量(euclidean metric)(也称欧氏距离)是一个通常采用的距离定义，指在$m$维空间中两个点之间的真实距离，或者向量的自然长度(即该点到原点的距离)。在二维和三维空间中的欧氏距离就是两点之间的实际距离。\n",
    "\n",
    "距离公式：\n",
    "\n",
    "$$\n",
    "d\\left( x,y \\right) = \\sqrt{\\sum_{i}^{}(x_{i} - y_{i})^{2}}\n",
    "$$\n",
    "\n",
    "![img](images/16333182861.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a96486",
   "metadata": {},
   "source": [
    "# KNN算法\n",
    "\n",
    "1．$k$近邻法是基本且简单的分类与回归方法。$k$近邻法的基本做法是：对给定的训练实例点和输入实例点，首先确定输入实例点的$k$个最近邻训练实例点，然后利用这$k$个训练实例点的类的多数来预测输入实例点的类。\n",
    "\n",
    "2．$k$近邻模型对应于基于训练数据集对特征空间的一个划分。$k$近邻法中，当训练集、距离度量、$k$值及分类决策规则确定后，其结果唯一确定。\n",
    "\n",
    "3．$k$近邻法三要素：距离度量、$k$值的选择和分类决策规则。常用的距离度量是欧氏距离。$k$值小时，$k$近邻模型更复杂；$k$值大时，$k$近邻模型更简单。$k$值的选择反映了对近似误差与估计误差之间的权衡，通常由交叉验证选择最优的$k$。\n",
    "\n",
    "常用的分类决策规则是多数表决，对应于经验风险最小化。\n",
    "\n",
    "4．$k$近邻法的实现需要考虑如何快速搜索k个最近邻点。**kd**树是一种便于对k维空间中的数据进行快速检索的数据结构。kd树是二叉树，表示对$k$维空间的一个划分，其每个结点对应于$k$维空间划分中的一个超矩形区域。利用**kd**树可以省去对大部分数据点的搜索， 从而减少搜索的计算量。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
